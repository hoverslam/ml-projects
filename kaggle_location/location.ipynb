{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif, SelectKBest\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>437</th>\n",
       "      <th>438</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 448 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  class  1  2  3  4  5  6  7  8  ...  437  438  439  440  441  442  443  \\\n",
       "0   0     11  0  0  0  1  1  0  0  0  ...    0    0    0    0    1    0    0   \n",
       "1   1      3  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "2   2      9  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3   3      8  0  0  0  1  0  0  0  0  ...    0    0    0    0    1    0    0   \n",
       "4   4      3  0  1  0  0  0  0  0  0  ...    0    0    0    0    0    0    1   \n",
       "\n",
       "   444  445  446  \n",
       "0    0    0    0  \n",
       "1    0    0    0  \n",
       "2    0    0    0  \n",
       "3    0    0    0  \n",
       "4    0    0    0  \n",
       "\n",
       "[5 rows x 448 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"location_train.csv\")\n",
    "test = pd.read_csv(\"location_test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Columns: 448 entries, ID to 446\n",
      "dtypes: int64(448)\n",
      "memory usage: 13.7 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"ID\", \"class\"], axis=1)\n",
    "y_train = train[\"class\"]\n",
    "\n",
    "X_test = test.drop([\"ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>437</th>\n",
       "      <th>438</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 446 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4  5  6  7  8  9  10  ...  437  438  439  440  441  442  443  444  \\\n",
       "0  0  0  0  1  1  0  0  0  0   0  ...    0    0    0    0    1    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0    0   \n",
       "2  0  0  0  0  0  0  0  0  1   0  ...    0    0    0    0    0    0    0    0   \n",
       "3  0  0  0  1  0  0  0  0  0   1  ...    0    0    0    0    1    0    0    0   \n",
       "4  0  1  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    1    0   \n",
       "\n",
       "   445  446  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "2    0    0  \n",
       "3    0    0  \n",
       "4    0    0  \n",
       "\n",
       "[5 rows x 446 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "1     3\n",
       "2     9\n",
       "3     8\n",
       "4     3\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "      ..\n",
       "442    0\n",
       "443    0\n",
       "444    0\n",
       "445    0\n",
       "446    0\n",
       "Length: 446, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     132\n",
       "2     141\n",
       "3     124\n",
       "4     135\n",
       "5      80\n",
       "6     150\n",
       "7      90\n",
       "8     250\n",
       "9     114\n",
       "10    173\n",
       "11    149\n",
       "12    142\n",
       "13    103\n",
       "14     99\n",
       "15    171\n",
       "16     83\n",
       "17    144\n",
       "18    103\n",
       "19    146\n",
       "20    211\n",
       "21    181\n",
       "22     98\n",
       "23    128\n",
       "24    133\n",
       "25    100\n",
       "26    119\n",
       "27    126\n",
       "28    127\n",
       "29    113\n",
       "30    135\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appearence of each class\n",
    "\n",
    "y_train.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.014583\n",
      "Feature 1: 0.092786\n",
      "Feature 2: 0.013870\n",
      "Feature 3: 0.110993\n",
      "Feature 4: 0.010373\n",
      "Feature 5: 0.014040\n",
      "Feature 6: 0.004617\n",
      "Feature 7: 0.000796\n",
      "Feature 8: 0.029550\n",
      "Feature 9: 0.000000\n",
      "Feature 10: 0.004675\n",
      "Feature 11: 0.100075\n",
      "Feature 12: 0.039617\n",
      "Feature 13: 0.023830\n",
      "Feature 14: 0.015585\n",
      "Feature 15: 0.004610\n",
      "Feature 16: 0.030514\n",
      "Feature 17: 0.016107\n",
      "Feature 18: 0.002124\n",
      "Feature 19: 0.036870\n",
      "Feature 20: 0.045319\n",
      "Feature 21: 0.024021\n",
      "Feature 22: 0.041839\n",
      "Feature 23: 0.015496\n",
      "Feature 24: 0.096463\n",
      "Feature 25: 0.031122\n",
      "Feature 26: 0.074633\n",
      "Feature 27: 0.006672\n",
      "Feature 28: 0.038128\n",
      "Feature 29: 0.023642\n",
      "Feature 30: 0.030965\n",
      "Feature 31: 0.016234\n",
      "Feature 32: 0.032914\n",
      "Feature 33: 0.023767\n",
      "Feature 34: 0.014540\n",
      "Feature 35: 0.112063\n",
      "Feature 36: 0.024810\n",
      "Feature 37: 0.024566\n",
      "Feature 38: 0.000000\n",
      "Feature 39: 0.120795\n",
      "Feature 40: 0.016103\n",
      "Feature 41: 0.030119\n",
      "Feature 42: 0.008388\n",
      "Feature 43: 0.010859\n",
      "Feature 44: 0.015784\n",
      "Feature 45: 0.005231\n",
      "Feature 46: 0.047992\n",
      "Feature 47: 0.014652\n",
      "Feature 48: 0.018765\n",
      "Feature 49: 0.006915\n",
      "Feature 50: 0.065315\n",
      "Feature 51: 0.054352\n",
      "Feature 52: 0.020136\n",
      "Feature 53: 0.085690\n",
      "Feature 54: 0.019108\n",
      "Feature 55: 0.013778\n",
      "Feature 56: 0.014278\n",
      "Feature 57: 0.000000\n",
      "Feature 58: 0.007238\n",
      "Feature 59: 0.007130\n",
      "Feature 60: 0.000000\n",
      "Feature 61: 0.009989\n",
      "Feature 62: 0.000000\n",
      "Feature 63: 0.000000\n",
      "Feature 64: 0.000000\n",
      "Feature 65: 0.022131\n",
      "Feature 66: 0.076658\n",
      "Feature 67: 0.004511\n",
      "Feature 68: 0.000000\n",
      "Feature 69: 0.000000\n",
      "Feature 70: 0.025715\n",
      "Feature 71: 0.052355\n",
      "Feature 72: 0.002863\n",
      "Feature 73: 0.076126\n",
      "Feature 74: 0.052390\n",
      "Feature 75: 0.003914\n",
      "Feature 76: 0.010074\n",
      "Feature 77: 0.016395\n",
      "Feature 78: 0.000000\n",
      "Feature 79: 0.012185\n",
      "Feature 80: 0.000050\n",
      "Feature 81: 0.047555\n",
      "Feature 82: 0.029607\n",
      "Feature 83: 0.023729\n",
      "Feature 84: 0.020167\n",
      "Feature 85: 0.016173\n",
      "Feature 86: 0.016983\n",
      "Feature 87: 0.064856\n",
      "Feature 88: 0.078059\n",
      "Feature 89: 0.000000\n",
      "Feature 90: 0.023516\n",
      "Feature 91: 0.035563\n",
      "Feature 92: 0.016935\n",
      "Feature 93: 0.016208\n",
      "Feature 94: 0.004348\n",
      "Feature 95: 0.046733\n",
      "Feature 96: 0.059675\n",
      "Feature 97: 0.000000\n",
      "Feature 98: 0.026924\n",
      "Feature 99: 0.027089\n",
      "Feature 100: 0.023600\n",
      "Feature 101: 0.023842\n",
      "Feature 102: 0.029841\n",
      "Feature 103: 0.063377\n",
      "Feature 104: 0.005607\n",
      "Feature 105: 0.007227\n",
      "Feature 106: 0.035737\n",
      "Feature 107: 0.002032\n",
      "Feature 108: 0.003719\n",
      "Feature 109: 0.073402\n",
      "Feature 110: 0.050610\n",
      "Feature 111: 0.006999\n",
      "Feature 112: 0.000000\n",
      "Feature 113: 0.019347\n",
      "Feature 114: 0.000000\n",
      "Feature 115: 0.023234\n",
      "Feature 116: 0.062598\n",
      "Feature 117: 0.000000\n",
      "Feature 118: 0.023061\n",
      "Feature 119: 0.002922\n",
      "Feature 120: 0.000000\n",
      "Feature 121: 0.003895\n",
      "Feature 122: 0.020511\n",
      "Feature 123: 0.055768\n",
      "Feature 124: 0.005653\n",
      "Feature 125: 0.045859\n",
      "Feature 126: 0.069188\n",
      "Feature 127: 0.015325\n",
      "Feature 128: 0.000000\n",
      "Feature 129: 0.004293\n",
      "Feature 130: 0.000000\n",
      "Feature 131: 0.077705\n",
      "Feature 132: 0.008761\n",
      "Feature 133: 0.000249\n",
      "Feature 134: 0.036038\n",
      "Feature 135: 0.055717\n",
      "Feature 136: 0.000000\n",
      "Feature 137: 0.012478\n",
      "Feature 138: 0.025567\n",
      "Feature 139: 0.006852\n",
      "Feature 140: 0.021712\n",
      "Feature 141: 0.042762\n",
      "Feature 142: 0.046604\n",
      "Feature 143: 0.008956\n",
      "Feature 144: 0.007640\n",
      "Feature 145: 0.010682\n",
      "Feature 146: 0.041268\n",
      "Feature 147: 0.048347\n",
      "Feature 148: 0.000000\n",
      "Feature 149: 0.029128\n",
      "Feature 150: 0.011628\n",
      "Feature 151: 0.028172\n",
      "Feature 152: 0.043886\n",
      "Feature 153: 0.000000\n",
      "Feature 154: 0.063116\n",
      "Feature 155: 0.112662\n",
      "Feature 156: 0.019435\n",
      "Feature 157: 0.007462\n",
      "Feature 158: 0.025719\n",
      "Feature 159: 0.018178\n",
      "Feature 160: 0.028577\n",
      "Feature 161: 0.055930\n",
      "Feature 162: 0.024419\n",
      "Feature 163: 0.114692\n",
      "Feature 164: 0.007133\n",
      "Feature 165: 0.025036\n",
      "Feature 166: 0.014245\n",
      "Feature 167: 0.007386\n",
      "Feature 168: 0.000000\n",
      "Feature 169: 0.019503\n",
      "Feature 170: 0.044884\n",
      "Feature 171: 0.014150\n",
      "Feature 172: 0.024362\n",
      "Feature 173: 0.067521\n",
      "Feature 174: 0.017543\n",
      "Feature 175: 0.042651\n",
      "Feature 176: 0.046019\n",
      "Feature 177: 0.020915\n",
      "Feature 178: 0.009896\n",
      "Feature 179: 0.030347\n",
      "Feature 180: 0.000000\n",
      "Feature 181: 0.108460\n",
      "Feature 182: 0.024362\n",
      "Feature 183: 0.016641\n",
      "Feature 184: 0.007573\n",
      "Feature 185: 0.000000\n",
      "Feature 186: 0.086813\n",
      "Feature 187: 0.000000\n",
      "Feature 188: 0.005608\n",
      "Feature 189: 0.002101\n",
      "Feature 190: 0.020366\n",
      "Feature 191: 0.094824\n",
      "Feature 192: 0.010613\n",
      "Feature 193: 0.000000\n",
      "Feature 194: 0.059369\n",
      "Feature 195: 0.069098\n",
      "Feature 196: 0.011916\n",
      "Feature 197: 0.095614\n",
      "Feature 198: 0.043827\n",
      "Feature 199: 0.016011\n",
      "Feature 200: 0.010977\n",
      "Feature 201: 0.033256\n",
      "Feature 202: 0.008705\n",
      "Feature 203: 0.076844\n",
      "Feature 204: 0.019939\n",
      "Feature 205: 0.071461\n",
      "Feature 206: 0.010596\n",
      "Feature 207: 0.048592\n",
      "Feature 208: 0.065181\n",
      "Feature 209: 0.065787\n",
      "Feature 210: 0.100160\n",
      "Feature 211: 0.047237\n",
      "Feature 212: 0.055585\n",
      "Feature 213: 0.017999\n",
      "Feature 214: 0.000000\n",
      "Feature 215: 0.012060\n",
      "Feature 216: 0.013492\n",
      "Feature 217: 0.071950\n",
      "Feature 218: 0.017022\n",
      "Feature 219: 0.042759\n",
      "Feature 220: 0.017242\n",
      "Feature 221: 0.021107\n",
      "Feature 222: 0.000000\n",
      "Feature 223: 0.012070\n",
      "Feature 224: 0.014343\n",
      "Feature 225: 0.000000\n",
      "Feature 226: 0.000000\n",
      "Feature 227: 0.078253\n",
      "Feature 228: 0.116535\n",
      "Feature 229: 0.003690\n",
      "Feature 230: 0.056398\n",
      "Feature 231: 0.015783\n",
      "Feature 232: 0.001104\n",
      "Feature 233: 0.018713\n",
      "Feature 234: 0.025790\n",
      "Feature 235: 0.011404\n",
      "Feature 236: 0.002703\n",
      "Feature 237: 0.030246\n",
      "Feature 238: 0.036709\n",
      "Feature 239: 0.020181\n",
      "Feature 240: 0.018168\n",
      "Feature 241: 0.030796\n",
      "Feature 242: 0.020543\n",
      "Feature 243: 0.006217\n",
      "Feature 244: 0.025637\n",
      "Feature 245: 0.032585\n",
      "Feature 246: 0.016712\n",
      "Feature 247: 0.017776\n",
      "Feature 248: 0.066199\n",
      "Feature 249: 0.021408\n",
      "Feature 250: 0.007211\n",
      "Feature 251: 0.007239\n",
      "Feature 252: 0.020494\n",
      "Feature 253: 0.002225\n",
      "Feature 254: 0.000000\n",
      "Feature 255: 0.021462\n",
      "Feature 256: 0.092566\n",
      "Feature 257: 0.067196\n",
      "Feature 258: 0.097960\n",
      "Feature 259: 0.003848\n",
      "Feature 260: 0.000000\n",
      "Feature 261: 0.008422\n",
      "Feature 262: 0.003153\n",
      "Feature 263: 0.025202\n",
      "Feature 264: 0.010905\n",
      "Feature 265: 0.020804\n",
      "Feature 266: 0.011361\n",
      "Feature 267: 0.004794\n",
      "Feature 268: 0.051763\n",
      "Feature 269: 0.012020\n",
      "Feature 270: 0.034782\n",
      "Feature 271: 0.054573\n",
      "Feature 272: 0.019413\n",
      "Feature 273: 0.038857\n",
      "Feature 274: 0.061959\n",
      "Feature 275: 0.004374\n",
      "Feature 276: 0.022564\n",
      "Feature 277: 0.004939\n",
      "Feature 278: 0.001360\n",
      "Feature 279: 0.010750\n",
      "Feature 280: 0.000000\n",
      "Feature 281: 0.015380\n",
      "Feature 282: 0.069587\n",
      "Feature 283: 0.086788\n",
      "Feature 284: 0.000000\n",
      "Feature 285: 0.057101\n",
      "Feature 286: 0.030174\n",
      "Feature 287: 0.059210\n",
      "Feature 288: 0.016187\n",
      "Feature 289: 0.006512\n",
      "Feature 290: 0.034051\n",
      "Feature 291: 0.004021\n",
      "Feature 292: 0.040265\n",
      "Feature 293: 0.051941\n",
      "Feature 294: 0.082171\n",
      "Feature 295: 0.092239\n",
      "Feature 296: 0.060668\n",
      "Feature 297: 0.000000\n",
      "Feature 298: 0.014424\n",
      "Feature 299: 0.030031\n",
      "Feature 300: 0.053026\n",
      "Feature 301: 0.011001\n",
      "Feature 302: 0.021199\n",
      "Feature 303: 0.000000\n",
      "Feature 304: 0.000000\n",
      "Feature 305: 0.000000\n",
      "Feature 306: 0.014297\n",
      "Feature 307: 0.075705\n",
      "Feature 308: 0.059486\n",
      "Feature 309: 0.011306\n",
      "Feature 310: 0.026418\n",
      "Feature 311: 0.031817\n",
      "Feature 312: 0.000000\n",
      "Feature 313: 0.042289\n",
      "Feature 314: 0.005928\n",
      "Feature 315: 0.016154\n",
      "Feature 316: 0.002794\n",
      "Feature 317: 0.047237\n",
      "Feature 318: 0.034701\n",
      "Feature 319: 0.027659\n",
      "Feature 320: 0.042646\n",
      "Feature 321: 0.047674\n",
      "Feature 322: 0.008166\n",
      "Feature 323: 0.064970\n",
      "Feature 324: 0.000694\n",
      "Feature 325: 0.005854\n",
      "Feature 326: 0.018320\n",
      "Feature 327: 0.007020\n",
      "Feature 328: 0.032640\n",
      "Feature 329: 0.003665\n",
      "Feature 330: 0.004798\n",
      "Feature 331: 0.054956\n",
      "Feature 332: 0.013122\n",
      "Feature 333: 0.030983\n",
      "Feature 334: 0.026946\n",
      "Feature 335: 0.019080\n",
      "Feature 336: 0.057478\n",
      "Feature 337: 0.004226\n",
      "Feature 338: 0.004724\n",
      "Feature 339: 0.014702\n",
      "Feature 340: 0.009545\n",
      "Feature 341: 0.016891\n",
      "Feature 342: 0.068769\n",
      "Feature 343: 0.017101\n",
      "Feature 344: 0.009519\n",
      "Feature 345: 0.085948\n",
      "Feature 346: 0.069303\n",
      "Feature 347: 0.054985\n",
      "Feature 348: 0.003862\n",
      "Feature 349: 0.029930\n",
      "Feature 350: 0.028696\n",
      "Feature 351: 0.025098\n",
      "Feature 352: 0.027134\n",
      "Feature 353: 0.022506\n",
      "Feature 354: 0.028134\n",
      "Feature 355: 0.006580\n",
      "Feature 356: 0.043266\n",
      "Feature 357: 0.000000\n",
      "Feature 358: 0.033072\n",
      "Feature 359: 0.008813\n",
      "Feature 360: 0.000000\n",
      "Feature 361: 0.077346\n",
      "Feature 362: 0.043639\n",
      "Feature 363: 0.005248\n",
      "Feature 364: 0.000000\n",
      "Feature 365: 0.037938\n",
      "Feature 366: 0.009922\n",
      "Feature 367: 0.022882\n",
      "Feature 368: 0.082693\n",
      "Feature 369: 0.054088\n",
      "Feature 370: 0.000000\n",
      "Feature 371: 0.015754\n",
      "Feature 372: 0.064445\n",
      "Feature 373: 0.033382\n",
      "Feature 374: 0.025858\n",
      "Feature 375: 0.008891\n",
      "Feature 376: 0.018990\n",
      "Feature 377: 0.000000\n",
      "Feature 378: 0.016280\n",
      "Feature 379: 0.017037\n",
      "Feature 380: 0.007144\n",
      "Feature 381: 0.010577\n",
      "Feature 382: 0.041714\n",
      "Feature 383: 0.052615\n",
      "Feature 384: 0.021322\n",
      "Feature 385: 0.058244\n",
      "Feature 386: 0.000000\n",
      "Feature 387: 0.049694\n",
      "Feature 388: 0.075540\n",
      "Feature 389: 0.009560\n",
      "Feature 390: 0.031853\n",
      "Feature 391: 0.000000\n",
      "Feature 392: 0.016922\n",
      "Feature 393: 0.000000\n",
      "Feature 394: 0.002232\n",
      "Feature 395: 0.042786\n",
      "Feature 396: 0.051482\n",
      "Feature 397: 0.074930\n",
      "Feature 398: 0.000000\n",
      "Feature 399: 0.003999\n",
      "Feature 400: 0.004677\n",
      "Feature 401: 0.035827\n",
      "Feature 402: 0.032521\n",
      "Feature 403: 0.001716\n",
      "Feature 404: 0.029982\n",
      "Feature 405: 0.047975\n",
      "Feature 406: 0.009039\n",
      "Feature 407: 0.060793\n",
      "Feature 408: 0.051017\n",
      "Feature 409: 0.088994\n",
      "Feature 410: 0.113512\n",
      "Feature 411: 0.002258\n",
      "Feature 412: 0.000000\n",
      "Feature 413: 0.021258\n",
      "Feature 414: 0.022172\n",
      "Feature 415: 0.041338\n",
      "Feature 416: 0.003667\n",
      "Feature 417: 0.008727\n",
      "Feature 418: 0.004751\n",
      "Feature 419: 0.000000\n",
      "Feature 420: 0.001770\n",
      "Feature 421: 0.033706\n",
      "Feature 422: 0.069390\n",
      "Feature 423: 0.126012\n",
      "Feature 424: 0.000000\n",
      "Feature 425: 0.020410\n",
      "Feature 426: 0.053105\n",
      "Feature 427: 0.047436\n",
      "Feature 428: 0.000000\n",
      "Feature 429: 0.019235\n",
      "Feature 430: 0.044324\n",
      "Feature 431: 0.004660\n",
      "Feature 432: 0.014926\n",
      "Feature 433: 0.011304\n",
      "Feature 434: 0.007005\n",
      "Feature 435: 0.013904\n",
      "Feature 436: 0.022017\n",
      "Feature 437: 0.041685\n",
      "Feature 438: 0.044199\n",
      "Feature 439: 0.031492\n",
      "Feature 440: 0.018615\n",
      "Feature 441: 0.012602\n",
      "Feature 442: 0.089528\n",
      "Feature 443: 0.054845\n",
      "Feature 444: 0.129250\n",
      "Feature 445: 0.080772\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/feature-selection-with-categorical-data/\n",
    "\n",
    "fs = SelectKBest(score_func=mutual_info_classif, k=300)\n",
    "fs.fit(X_train, y_train)\n",
    "X_train_fs = fs.transform(X_train)\n",
    "X_test_fs = fs.transform(X_test)\n",
    "\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Grid Search to find best hyperparameters for different classifier\n",
    "\n",
    "cv = 5          # number of folds\n",
    "verbose = 1     # information shown during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 98 candidates, totalling 490 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>param_metric</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40</td>\n",
       "      <td>distance</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.50575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>40</td>\n",
       "      <td>distance</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.50550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40</td>\n",
       "      <td>distance</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.50550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.50200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>distance</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.50150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>distance</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.50150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>30</td>\n",
       "      <td>distance</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.50150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>uniform</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.49775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_neighbors param_weights param_metric  mean_test_score\n",
       "25                40      distance    manhattan          0.50575\n",
       "53                40      distance    minkowski          0.50550\n",
       "11                40      distance    euclidean          0.50550\n",
       "27                50      distance    manhattan          0.50200\n",
       "23                30      distance    manhattan          0.50150\n",
       "9                 30      distance    euclidean          0.50150\n",
       "51                30      distance    minkowski          0.50150\n",
       "13                50      distance    euclidean          0.50025\n",
       "55                50      distance    minkowski          0.50025\n",
       "10                40       uniform    euclidean          0.49775"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"n_neighbors\":[1, 5, 10, 20, 30, 40, 50], \n",
    "    \"weights\":[\"uniform\", \"distance\"],\n",
    "    \"metric\":[\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\", \"wminkowski\", \"seuclidean\", \"mahalanobis\"]}\n",
    "knn = GridSearchCV(neighbors.KNeighborsClassifier(), parameters, cv=cv, verbose=verbose)\n",
    "knn.fit(X_train_fs, y_train)\n",
    "\n",
    "knn_results = pd.DataFrame(knn.cv_results_)\n",
    "knn_results= knn_results[[\"param_n_neighbors\", \"param_weights\", \"param_metric\", \"mean_test_score\"]]\n",
    "knn_results.sort_values([\"mean_test_score\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.24775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.24675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.24500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.24425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.24275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.24275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.24025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.23975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.23950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.23775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_criterion param_splitter param_max_depth param_max_features  \\\n",
       "12            gini           best              10               auto   \n",
       "19            gini         random              20               auto   \n",
       "13            gini         random              10               auto   \n",
       "20            gini           best              20               sqrt   \n",
       "18            gini           best              20               auto   \n",
       "15            gini         random              10               sqrt   \n",
       "14            gini           best              10               sqrt   \n",
       "24            gini           best              30               auto   \n",
       "42         entropy           best              10               auto   \n",
       "25            gini         random              30               auto   \n",
       "\n",
       "    mean_test_score  \n",
       "12          0.24775  \n",
       "19          0.24675  \n",
       "13          0.24500  \n",
       "20          0.24425  \n",
       "18          0.24275  \n",
       "15          0.24275  \n",
       "14          0.24025  \n",
       "24          0.23975  \n",
       "42          0.23950  \n",
       "25          0.23775  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"criterion\":[\"gini\", \"entropy\"],\n",
    "    \"splitter\":[\"best\", \"random\"], \n",
    "    \"max_depth\":[\"None\", 5, 10, 20, 30],\n",
    "    \"max_features\":[\"auto\", \"sqrt\", \"log2\"]}\n",
    "dt = GridSearchCV(DecisionTreeClassifier(), parameters, cv=cv, verbose=verbose)\n",
    "dt.fit(X_train_fs, y_train)\n",
    "\n",
    "dt_results = pd.DataFrame(dt.cv_results_)\n",
    "dt_results = dt_results[[\"param_criterion\", \"param_splitter\", \"param_max_depth\", \"param_max_features\", \"mean_test_score\"]]\n",
    "dt_results.sort_values([\"mean_test_score\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 168 candidates, totalling 840 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>500</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.53875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>300</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.53450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>400</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.53300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>500</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.53300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>400</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.53100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>500</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.53050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>200</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.52850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>400</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.52775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>400</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.52725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>300</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.52400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_n_estimators param_criterion param_max_depth param_max_features  \\\n",
       "83                 500            gini              20               log2   \n",
       "81                 300            gini              20               log2   \n",
       "82                 400            gini              20               log2   \n",
       "69                 500            gini              20               auto   \n",
       "75                 400            gini              20               sqrt   \n",
       "76                 500            gini              20               sqrt   \n",
       "80                 200            gini              20               log2   \n",
       "68                 400            gini              20               auto   \n",
       "166                400         entropy              20               log2   \n",
       "74                 300            gini              20               sqrt   \n",
       "\n",
       "     mean_test_score  \n",
       "83           0.53875  \n",
       "81           0.53450  \n",
       "82           0.53300  \n",
       "69           0.53300  \n",
       "75           0.53100  \n",
       "76           0.53050  \n",
       "80           0.52850  \n",
       "68           0.52775  \n",
       "166          0.52725  \n",
       "74           0.52400  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\":[10, 50, 100, 200, 300, 400, 500], \n",
    "    \"criterion\":[\"gini\", \"entropy\"], \n",
    "    \"max_depth\":[\"None\", 5, 10, 20],\n",
    "    \"max_features\":[\"auto\", \"sqrt\", \"log2\"]}\n",
    "rf = GridSearchCV(RandomForestClassifier(), parameters, cv=cv, verbose=verbose)\n",
    "rf.fit(X_train_fs, y_train)\n",
    "\n",
    "rf_results = pd.DataFrame(rf.cv_results_)\n",
    "rf_results = rf_results[[\"param_n_estimators\", \"param_criterion\", \"param_max_depth\", \"param_max_features\", \"mean_test_score\"]]\n",
    "rf_results.sort_values([\"mean_test_score\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"C\":[1, 5, 10, 20],\n",
    "    \"kernel\":[\"linear\", \"sigmoid\", \"rbf\", \"poly\"],     \n",
    "    \"degree\":[3, 5],\n",
    "    \"gamma\":[\"scale\", \"auto\"],\n",
    "    \"class_weight\":[\"None\", \"balanced\"]}\n",
    "svm = GridSearchCV(svm.SVC(), parameters, cv=cv, verbose=verbose)\n",
    "svm.fit(X_train_fs, y_train)\n",
    "\n",
    "svm_results = pd.DataFrame(svm.cv_results_)\n",
    "svm_results = svm_results[[\"param_C\", \"param_kernel\", \"param_degree\", \"param_gamma\", \"param_class_weight\", \"mean_test_score\"]]\n",
    "svm_results.sort_values([\"mean_test_score\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.58350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.57725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>l2</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.57175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.57175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>l2</td>\n",
       "      <td>20</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.57025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>l1</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.56975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>l1</td>\n",
       "      <td>20</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.56950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>l1</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.56925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.56825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.56700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_penalty param_C param_class_weight  mean_test_score\n",
       "5             l2       1           balanced          0.58350\n",
       "4             l1       1           balanced          0.57725\n",
       "13            l2       5           balanced          0.57175\n",
       "21            l2      10           balanced          0.57175\n",
       "29            l2      20           balanced          0.57025\n",
       "12            l1       5           balanced          0.56975\n",
       "28            l1      20           balanced          0.56950\n",
       "20            l1      10           balanced          0.56925\n",
       "23          none      10           balanced          0.56825\n",
       "7           none       1           balanced          0.56700"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"penalty\":[\"l1\", \"l2\", \"elasticnet\", \"none\"], \n",
    "    \"C\":[1, 5, 10, 20],\n",
    "    \"class_weight\":[\"None\", \"balanced\"],\n",
    "    \"solver\":[\"saga\"]}\n",
    "logreg = GridSearchCV(LogisticRegression(), parameters, cv=cv, verbose=verbose)\n",
    "logreg.fit(X_train_fs, y_train)\n",
    "\n",
    "logreg_results = pd.DataFrame(logreg.cv_results_)\n",
    "logreg_results = logreg_results[[\"param_penalty\", \"param_C\", \"param_class_weight\", \"mean_test_score\"]]\n",
    "logreg_results.sort_values([\"mean_test_score\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>log</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.56525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>log</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.55350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>log</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.53950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>modified_huber</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.53800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.52775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.52225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>log</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.52000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hinge</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.51550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>log</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.51550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        param_loss param_penalty param_alpha  mean_test_score\n",
       "33             log            l2        0.01          0.56525\n",
       "18             log            l2       0.001          0.55350\n",
       "20             log    elasticnet       0.001          0.55000\n",
       "36  modified_huber            l2        0.01          0.53950\n",
       "38  modified_huber    elasticnet        0.01          0.53800\n",
       "30           hinge            l2        0.01          0.52775\n",
       "15           hinge            l2       0.001          0.52225\n",
       "19             log            l1       0.001          0.52000\n",
       "17           hinge    elasticnet       0.001          0.51550\n",
       "35             log    elasticnet        0.01          0.51550"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"loss\":[\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"], \n",
    "    \"penalty\":[\"l2\", \"l1\", \"elasticnet\"],\n",
    "    \"alpha\":[0.0001, 0.001, 0.01]}\n",
    "sgd = GridSearchCV(SGDClassifier(), parameters, cv=cv, verbose=verbose)\n",
    "sgd.fit(X_train_fs, y_train)\n",
    "\n",
    "sgd_results = pd.DataFrame(sgd.cv_results_)\n",
    "sgd_results = sgd_results[[\"param_loss\", \"param_penalty\", \"param_alpha\", \"mean_test_score\"]]\n",
    "sgd_results.sort_values([\"mean_test_score\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results in markdown table\n",
    "\n",
    "# result = knn_results\n",
    "# print(result.sort_values([\"mean_test_score\"], ascending=False).head(20).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(C=5, kernel=\"rbf\", gamma=\"scale\")\n",
    "model.fit(X_train_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(test[\"ID\"])\n",
    "predictions[\"class\"] = model.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08ed10a1276613731008dc950927347abb3e57cb34eda9264fef37959574a2d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
